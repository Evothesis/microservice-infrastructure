import json
import boto3
import hashlib
import uuid
from datetime import datetime, timezone, timedelta
from decimal import Decimal
import os
import re
from typing import Dict, List, Optional, Tuple
import user_agents

# Initialize AWS clients
dynamodb = boto3.resource('dynamodb')
s3_client = boto3.client('s3')

# Environment variables
RAW_EVENTS_TABLE = os.environ.get('RAW_EVENTS_TABLE')
IDENTITIES_TABLE = os.environ.get('IDENTITIES_TABLE')
SESSIONS_TABLE = os.environ.get('SESSIONS_TABLE')
ENRICHED_S3_BUCKET = os.environ.get('ENRICHED_S3_BUCKET')
ENVIRONMENT = os.environ.get('ENVIRONMENT', 'dev')

# Initialize DynamoDB tables
raw_events_table = dynamodb.Table(RAW_EVENTS_TABLE)
identities_table = dynamodb.Table(IDENTITIES_TABLE)
sessions_table = dynamodb.Table(SESSIONS_TABLE)

def lambda_handler(event, context):
    """
    Process DynamoDB stream events for identity resolution and enrichment
    """
    print(f"Processing {len(event.get('Records', []))} stream records")
    
    enriched_events = []
    
    for record in event.get('Records', []):
        try:
            # Only process INSERT events (new events)
            if record['eventName'] != 'INSERT':
                continue
                
            # Extract the new event data
            raw_event = record['dynamodb']['NewImage']
            parsed_event = parse_dynamodb_item(raw_event)
            
            print(f"Processing event: {parsed_event.get('eventId', 'unknown')}")
            
            # Perform identity resolution
            enriched_event = enrich_event(parsed_event, context)
            enriched_events.append(enriched_event)
            
        except Exception as e:
            print(f"Error processing record: {str(e)}")
            print(f"Record: {json.dumps(record, default=str)}")
            continue
    
    # Store enriched events in S3
    if enriched_events:
        store_enriched_events(enriched_events)
    
    return {
        'statusCode': 200,
        'body': json.dumps({
            'processed_events': len(enriched_events),
            'timestamp': datetime.utcnow().isoformat()
        })
    }

def parse_dynamodb_item(dynamodb_item: Dict) -> Dict:
    """Convert DynamoDB item format to regular Python dict"""
    def parse_value(value):
        if 'S' in value:
            return value['S']
        elif 'N' in value:
            return float(value['N'])
        elif 'BOOL' in value:
            return value['BOOL']
        elif 'M' in value:
            return {k: parse_value(v) for k, v in value['M'].items()}
        elif 'L' in value:
            return [parse_value(item) for item in value['L']]
        elif 'NULL' in value:
            return None
        else:
            return value
    
    return {key: parse_value(value) for key, value in dynamodb_item.items()}

def enrich_event(raw_event: Dict, context) -> Dict:
    """Main enrichment function"""
    
    # Extract key fields
    event_id = raw_event.get('eventId', '')
    site_id = raw_event.get('siteId', '')
    session_id = raw_event.get('sessionId', '')
    visitor_id = raw_event.get('visitorId', '')
    ip_address = raw_event.get('ip', '')
    user_agent = raw_event.get('userAgent', '')
    timestamp = raw_event.get('timestamp', 0)
    
    # Generate device fingerprint
    device_fingerprint = generate_device_fingerprint(raw_event)
    
    # Extract IP subnet for household grouping
    ip_subnet = extract_ip_subnet(ip_address)
    
    # Resolve identity
    identity_data = resolve_identity(
        device_fingerprint, 
        ip_subnet, 
        raw_event
    )
    
    # Update session tracking
    session_data = update_session_tracking(
        identity_data['identity_id'],
        session_id,
        site_id,
        raw_event,
        timestamp  # Pass timestamp separately
    )
    
    # Normalize and classify data
    normalized_data = normalize_event_data(raw_event)
    
    # Calculate confidence score
    confidence_score = calculate_identity_confidence({
        'device_fingerprint': device_fingerprint,
        'ip_stability': identity_data.get('ip_stability', 0.5),
        'behavioral_consistency': 0.8,  # Placeholder - implement behavioral analysis
        'temporal_patterns': 0.7  # Placeholder - implement timing analysis
    })
    
    # Create enriched event
    enriched_event = {
        **raw_event,  # Include all original data
        'identity': {
            'identity_id': identity_data['identity_id'],
            'household_id': identity_data['household_id'],
            'device_fingerprint': device_fingerprint,
            'session_sequence': session_data['session_sequence'],
            'is_new_visitor': identity_data['is_new_visitor'],
            'total_sessions': identity_data['session_count'],
            'confidence_score': confidence_score
        },
        'normalized': normalized_data,
        'enrichment_metadata': {
            'processed_at': datetime.utcnow().isoformat(),
            'enrichment_version': '1.0',
            'lambda_request_id': getattr(context, 'aws_request_id', 'unknown')
        }
    }
    
    return enriched_event

def generate_device_fingerprint(event_data: Dict) -> str:
    """Generate a device fingerprint from browser data"""
    
    # Extract browser data
    browser_data = event_data.get('data', {}).get('browser', {})
    user_agent = event_data.get('userAgent', '')
    
    # Create fingerprint components
    fingerprint_components = {
        'screen_resolution': f"{browser_data.get('screenWidth', 0)}x{browser_data.get('screenHeight', 0)}",
        'viewport_size': f"{browser_data.get('viewportWidth', 0)}x{browser_data.get('viewportHeight', 0)}",
        'user_agent_hash': hashlib.sha256(user_agent.encode()).hexdigest()[:16],
        'timezone': browser_data.get('timezone', 'unknown'),
        'language': browser_data.get('language', 'unknown'),
        'device_pixel_ratio': str(browser_data.get('devicePixelRatio', 1)),
        'platform': extract_platform(user_agent)
    }
    
    # Create stable fingerprint
    fingerprint_string = json.dumps(fingerprint_components, sort_keys=True)
    fingerprint_hash = hashlib.sha256(fingerprint_string.encode()).hexdigest()
    
    return f"fp_{fingerprint_hash[:16]}"

def extract_ip_subnet(ip_address: str) -> str:
    """Extract /24 subnet from IP address for household grouping"""
    if not ip_address or ip_address == 'unknown':
        return 'unknown'
    
    try:
        # Handle IPv4
        if '.' in ip_address:
            octets = ip_address.split('.')
            if len(octets) >= 3:
                return f"{octets[0]}.{octets[1]}.{octets[2]}.0/24"
        
        # Handle IPv6 (simplified - use first 64 bits)
        elif ':' in ip_address:
            parts = ip_address.split(':')
            if len(parts) >= 4:
                return f"{parts[0]}:{parts[1]}:{parts[2]}:{parts[3]}::/64"
    
    except Exception as e:
        print(f"Error extracting IP subnet from {ip_address}: {e}")
    
    return 'unknown'

def extract_platform(user_agent: str) -> str:
    """Extract platform/OS from user agent"""
    if not user_agent:
        return 'unknown'
    
    try:
        parsed = user_agents.parse(user_agent)
        return f"{parsed.os.family}_{parsed.device.family}".lower().replace(' ', '_')
    except:
        # Fallback to simple detection
        ua_lower = user_agent.lower()
        if 'windows' in ua_lower:
            return 'windows'
        elif 'mac' in ua_lower or 'darwin' in ua_lower:
            return 'macos'
        elif 'android' in ua_lower:
            return 'android'
        elif 'iphone' in ua_lower or 'ios' in ua_lower:
            return 'ios'
        elif 'linux' in ua_lower:
            return 'linux'
        else:
            return 'unknown'

def resolve_identity(device_fingerprint: str, ip_subnet: str, event_data: Dict) -> Dict:
    """Resolve visitor identity using device fingerprint and IP subnet"""
    
    current_hour = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    ip_subnet_hour = f"{ip_subnet}#{current_hour.strftime('%Y-%m-%d-%H')}"
    
    try:
        # Look for existing identity
        response = identities_table.get_item(
            Key={
                'device_fingerprint': device_fingerprint,
                'ip_subnet_hour': ip_subnet_hour
            }
        )
        
        if 'Item' in response:
            # Update existing identity
            identity = response['Item']
            
            # Store in DynamoDB
            identities_table.update_item(
                Key={
                    'device_fingerprint': device_fingerprint,
                    'ip_subnet_hour': ip_subnet_hour
                },
                UpdateExpression='SET last_seen = :ts, total_events = total_events + :inc',
                ExpressionAttributeValues={
                    ':ts': Decimal(str(event_data.get('timestamp', 0))),
                    ':inc': 1
                }
            )
            
            return {
                'identity_id': identity['identity_id'],
                'household_id': identity['household_id'],
                'is_new_visitor': False,
                'session_count': identity.get('session_count', 1),
                'ip_stability': 0.9  # High stability for existing identity
            }
        
        else:
            # Create new identity
            identity_id = f"id_{uuid.uuid4().hex[:12]}"
            household_id = f"hh_{hashlib.sha256(ip_subnet.encode()).hexdigest()[:12]}"
            
            # Check if there are other devices in this household
            household_devices = check_household_devices(household_id, current_hour)
            is_new_household = len(household_devices) == 0
            
            # Store new identity
            identities_table.put_item(
                Item={
                    'device_fingerprint': device_fingerprint,
                    'ip_subnet_hour': ip_subnet_hour,
                    'identity_id': identity_id,
                    'household_id': household_id,
                    'first_seen': Decimal(str(event_data.get('timestamp', 0))),
                    'last_seen': Decimal(str(event_data.get('timestamp', 0))),
                    'session_count': 1,
                    'total_events': 1,
                    'ip_subnet': ip_subnet,
                    'created_at': datetime.utcnow().isoformat(),
                    'ttl': int((datetime.utcnow() + timedelta(days=180)).timestamp())
                }
            )
            
            return {
                'identity_id': identity_id,
                'household_id': household_id,
                'is_new_visitor': True,
                'session_count': 1,
                'ip_stability': 0.5  # Moderate stability for new identity
            }
            
    except Exception as e:
        print(f"Error resolving identity: {e}")
        # Fallback to session-based identity
        return {
            'identity_id': f"fallback_{event_data.get('sessionId', 'unknown')}",
            'household_id': f"hh_fallback_{hashlib.sha256(ip_subnet.encode()).hexdigest()[:12]}",
            'is_new_visitor': True,
            'session_count': 1,
            'ip_stability': 0.3
        }

def check_household_devices(household_id: str, current_hour: datetime) -> List[Dict]:
    """Check for other devices in the same household"""
    try:
        # Query for devices in the same hour (simplified approach)
        # In production, you might want to check a wider time window
        response = identities_table.scan(
            FilterExpression='household_id = :hh_id',
            ExpressionAttributeValues={':hh_id': household_id},
            Limit=10  # Reasonable limit for household size
        )
        
        return response.get('Items', [])
        
    except Exception as e:
        print(f"Error checking household devices: {e}")
        return []

def update_session_tracking(identity_id: str, session_id: str, site_id: str, event_data: Dict, timestamp: float) -> Dict:
    """Update session tracking for the identity"""
    
    try:
        # Check if session already exists
        response = sessions_table.get_item(
            Key={
                'identity_id': identity_id,
                'session_start': Decimal(str(timestamp))
            }
        )
        
        if 'Item' in response:
            # Update existing session
            sessions_table.update_item(
                Key={
                    'identity_id': identity_id,
                    'session_start': Decimal(str(timestamp))
                },
                UpdateExpression='SET total_events = total_events + :inc, last_activity = :ts',
                ExpressionAttributeValues={
                    ':inc': 1,
                    ':ts': Decimal(str(timestamp))
                }
            )
            
            return {'session_sequence': response['Item'].get('session_sequence', 1)}
        
        else:
            # Count existing sessions for this identity
            response = sessions_table.query(
                KeyConditionExpression='identity_id = :id',
                ExpressionAttributeValues={':id': identity_id},
                Select='COUNT'
            )
            
            session_sequence = response.get('Count', 0) + 1
            
            # Create new session record
            sessions_table.put_item(
                Item={
                    'identity_id': identity_id,
                    'session_start': Decimal(str(timestamp)),
                    'session_id': session_id,
                    'site_id': site_id,
                    'session_sequence': session_sequence,
                    'total_events': 1,
                    'first_event_type': event_data.get('eventType', 'unknown'),
                    'entry_page': event_data.get('path', ''),
                    'traffic_source': event_data.get('trafficSource', ''),
                    'created_at': datetime.utcnow().isoformat(),
                    'ttl': int((datetime.utcnow() + timedelta(days=180)).timestamp())
                }
            )
            
            return {'session_sequence': session_sequence}
            
    except Exception as e:
        print(f"Error updating session tracking: {e}")
        return {'session_sequence': 1}

def normalize_event_data(event_data: Dict) -> Dict:
    """Normalize and classify event data"""
    
    user_agent = event_data.get('userAgent', '')
    url = event_data.get('url', '')
    path = event_data.get('path', '')
    
    # Device classification
    device_category = classify_device(user_agent)
    browser_family, os_family = parse_user_agent(user_agent)
    
    # Page classification
    page_category = classify_page_type(path)
    
    # Traffic source normalization
    attribution = event_data.get('data', {}).get('attribution', {})
    traffic_source_category = normalize_traffic_source(attribution)
    
    return {
        'device_category': device_category,
        'browser_family': browser_family,
        'os_family': os_family,
        'page_category': page_category,
        'traffic_source_category': traffic_source_category,
        'is_mobile': device_category in ['mobile', 'tablet'],
        'url_domain': extract_domain(url),
        'url_path_depth': len([p for p in path.split('/') if p])
    }

def classify_device(user_agent: str) -> str:
    """Classify device type from user agent"""
    if not user_agent:
        return 'unknown'
    
    try:
        parsed = user_agents.parse(user_agent)
        if parsed.is_mobile:
            return 'mobile'
        elif parsed.is_tablet:
            return 'tablet'
        elif parsed.is_pc:
            return 'desktop'
        else:
            return 'other'
    except:
        # Fallback classification
        ua_lower = user_agent.lower()
        if any(mobile in ua_lower for mobile in ['mobile', 'android', 'iphone']):
            return 'mobile'
        elif any(tablet in ua_lower for tablet in ['ipad', 'tablet']):
            return 'tablet'
        else:
            return 'desktop'

def parse_user_agent(user_agent: str) -> Tuple[str, str]:
    """Parse browser and OS from user agent"""
    if not user_agent:
        return 'unknown', 'unknown'
    
    try:
        parsed = user_agents.parse(user_agent)
        browser_family = parsed.browser.family.lower().replace(' ', '_')
        os_family = parsed.os.family.lower().replace(' ', '_')
        return browser_family, os_family
    except:
        return 'unknown', 'unknown'

def classify_page_type(path: str) -> str:
    """Classify page type based on URL path"""
    if not path:
        return 'unknown'
    
    path_lower = path.lower()
    
    # Common page type patterns
    if path_lower in ['/', '/home', '/index']:
        return 'homepage'
    elif any(keyword in path_lower for keyword in ['/product', '/item', '/p/']):
        return 'product'
    elif any(keyword in path_lower for keyword in ['/category', '/collection', '/shop']):
        return 'category'
    elif any(keyword in path_lower for keyword in ['/cart', '/checkout', '/order']):
        return 'checkout'
    elif any(keyword in path_lower for keyword in ['/account', '/profile', '/dashboard']):
        return 'account'
    elif any(keyword in path_lower for keyword in ['/about', '/contact', '/help', '/faq']):
        return 'content'
    elif any(keyword in path_lower for keyword in ['/blog', '/news', '/article']):
        return 'content'
    else:
        return 'other'

def normalize_traffic_source(attribution: Dict) -> str:
    """Normalize traffic source category"""
    if not attribution:
        return 'direct'
    
    first_touch = attribution.get('firstTouch', {})
    category = first_touch.get('category', 'direct')
    
    # Normalize categories
    category_mapping = {
        'paid_search': 'paid',
        'paid_social': 'paid',
        'organic_search': 'organic',
        'organic_social': 'social',
        'email': 'email',
        'direct': 'direct',
        'referral': 'referral'
    }
    
    return category_mapping.get(category, 'other')

def extract_domain(url: str) -> str:
    """Extract domain from URL"""
    if not url:
        return 'unknown'
    
    try:
        from urllib.parse import urlparse
        parsed = urlparse(url)
        return parsed.netloc.lower()
    except:
        return 'unknown'

def calculate_identity_confidence(signals: Dict) -> float:
    """Calculate confidence score for identity resolution"""
    
    scores = {
        'device_fingerprint_uniqueness': 0.8,  # Placeholder - could calculate entropy
        'ip_stability': signals.get('ip_stability', 0.5),
        'behavioral_consistency': signals.get('behavioral_consistency', 0.7),
        'temporal_patterns': signals.get('temporal_patterns', 0.6)
    }
    
    # Weighted average
    weights = {
        'device_fingerprint_uniqueness': 0.4,
        'ip_stability': 0.3,
        'behavioral_consistency': 0.2,
        'temporal_patterns': 0.1
    }
    
    confidence = sum(scores[k] * weights[k] for k in scores if k in weights)
    return round(min(1.0, max(0.0, confidence)), 3)

def store_enriched_events(enriched_events: List[Dict]) -> None:
    """Store enriched events in S3 organized by site and hour"""
    
    # Group events by site and hour for efficient storage
    events_by_site_hour = {}
    
    for event in enriched_events:
        site_id = event.get('siteId', 'unknown')
        timestamp = event.get('timestamp', 0)
        
        # Convert timestamp to datetime
        if isinstance(timestamp, (int, float)):
            dt = datetime.fromtimestamp(timestamp / 1000, tz=timezone.utc)
        else:
            dt = datetime.now(timezone.utc)
        
        hour_key = f"{site_id}#{dt.strftime('%Y-%m-%d-%H')}"
        
        if hour_key not in events_by_site_hour:
            events_by_site_hour[hour_key] = []
        
        events_by_site_hour[hour_key].append(event)
    
    # Store each group in S3
    for hour_key, events in events_by_site_hour.items():
        try:
            site_id, hour_str = hour_key.split('#')
            clean_site_id = site_id.replace('.', '-').replace('/', '-').lower()
            
            # Parse hour string back to datetime for S3 key
            dt = datetime.strptime(hour_str, '%Y-%m-%d-%H')
            
            # Create S3 key with partitioning
            s3_key = (
                f"enriched-events/domain={clean_site_id}/"
                f"year={dt.year}/month={dt.month:02d}/"
                f"day={dt.day:02d}/hour={dt.hour:02d}/"
                f"enriched-{hour_str}-{uuid.uuid4().hex[:8]}.jsonl"
            )
            
            # Convert events to JSONL format
            jsonl_lines = []
            for event in events:
                # Convert Decimal types for JSON serialization
                event_json = json.dumps(event, default=decimal_default, separators=(',', ':'))
                jsonl_lines.append(event_json)
            
            jsonl_content = '\n'.join(jsonl_lines) + '\n'
            
            # Add metadata header
            metadata = {
                'enrichment_info': {
                    'site_id': site_id,
                    'hour': hour_str,
                    'event_count': len(events),
                    'enriched_at': datetime.utcnow().isoformat(),
                    'environment': ENVIRONMENT,
                    'enrichment_version': '1.0'
                }
            }
            
            final_content = json.dumps(metadata, default=decimal_default) + '\n' + jsonl_content
            
            # Upload to S3
            s3_client.put_object(
                Bucket=ENRICHED_S3_BUCKET,
                Key=s3_key,
                Body=final_content.encode('utf-8'),
                ContentType='application/jsonl',
                Metadata={
                    'site-id': site_id,
                    'event-count': str(len(events)),
                    'hour': hour_str,
                    'enrichment-version': '1.0',
                    'environment': ENVIRONMENT
                }
            )
            
            print(f"Stored {len(events)} enriched events for {site_id} at {s3_key}")
            
        except Exception as e:
            print(f"Error storing enriched events for {hour_key}: {e}")

def decimal_default(obj):
    """Convert Decimal types to float for JSON serialization"""
    if isinstance(obj, Decimal):
        return float(obj)
    raise TypeError(f"Object {obj} is not JSON serializable")